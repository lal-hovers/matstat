

## 1. Определение ковариации

Пусть заданы две случайные величины $X$ и $Y$ (дискретные или непрерывные) с конечными математическими ожиданиями $E(X)$ и $E(Y)$. 

**Ковариация** $X$ и $Y$ определяется как
$$
\mathrm{Cov}(X, Y) = E\bigl[(X - E(X))(Y - E(Y))\bigr].
$$

### 1.1. Альтернативное определение

Эквивалентно можно записать:
$$
\mathrm{Cov}(X, Y) = E(XY) - E(X)\,E(Y).
$$
Обе формулы дают один и тот же результат.

### 1.2. Дискретный случай

Если $X$ и $Y$ — дискретные случайные величины, принимающие значения $(x_i, y_j)$ с вероятностями $p_{ij} = P(X = x_i, Y = y_j)$, то
$$
\mathrm{Cov}(X, Y)
= \sum_{i,j} x_i \, y_j \, p_{ij} \;-\; \Bigl(\sum_{i,j} x_i \, p_{ij}\Bigr)\Bigl(\sum_{i,j} y_j \, p_{ij}\Bigr).
$$

### 1.3. Непрерывный случай

Если $X$ и $Y$ имеют совместную плотность $f_{X,Y}(x,y)$, то
$$
\mathrm{Cov}(X, Y)
= \iint x\,y \, f_{X,Y}(x,y)\, dx\, dy
\;-\;
\Bigl(\iint x \, f_{X,Y}(x,y)\, dx\, dy\Bigr)
\Bigl(\iint y \, f_{X,Y}(x,y)\, dx\, dy\Bigr).
$$

## 2. Свойства ковариации

1. **Билинейность**:
   - $\mathrm{Cov}(X + a, Y) = \mathrm{Cov}(X, Y)$, если $a$ — константа.
   - $\mathrm{Cov}(aX, bY) = ab\, \mathrm{Cov}(X, Y)$ для любых констант $a, b$.
2. **Симметричность**: 
   $$
   \mathrm{Cov}(X, Y) = \mathrm{Cov}(Y, X).
   $$
3. **$\mathrm{Cov}(X, X) = \mathrm{Var}(X)$** (дисперсия).
4. **Независимость и ковариация**:  
   Если $X$ и $Y$ **независимы**, то $\mathrm{Cov}(X, Y) = 0$. Но обратное не всегда верно: $\mathrm{Cov}(X, Y) = 0$ ещё не гарантирует независимость (может быть «нелинейная» зависимость).

## 3. Коэффициент корреляции

### 3.1. Определение

**Коэффициентом корреляции** (Пирсона) двух случайных величин $X$ и $Y$ называется величина
$$
\rho_{X,Y} = \frac{\mathrm{Cov}(X, Y)}{\sqrt{\mathrm{Var}(X)} \,\sqrt{\mathrm{Var}(Y)}}.
$$

- Он существует при условии, что $\mathrm{Var}(X)$ и $\mathrm{Var}(Y)$ конечны и положительны (то есть $\sigma_X, \sigma_Y > 0$).

### 3.2. Свойства

1. **Ограниченность**:
   $$
   -1 \;\le\; \rho_{X,Y} \;\le\; 1.
   $$
2. **Знак корреляции**:
   - Если $\rho_{X,Y} > 0$, говорят о положительной (прямой) линейной зависимости.
   - Если $\rho_{X,Y} < 0$, говорят об отрицательной (обратной) линейной зависимости.
   - Если $\rho_{X,Y} = 0$, корреляция отсутствует (линейная), но это не исключает возможных нелинейных связей.
3. **Пределы**:
   - $\rho_{X,Y} = 1$ тогда и только тогда, когда $Y = aX + b$ почти наверняка, с $a>0$ (идеальная положительная линейная связь).
   - $\rho_{X,Y} = -1$ тогда и только тогда, когда $Y = aX + b$ почти наверняка, с $a<0$ (идеальная отрицательная линейная связь).

## 4. Изображение качественной диаграммы рассеяния (облако данных) при разных значениях корреляции

Ниже описаны **типичные** «облака точек» (для выборок или случайных величин), соответствующие разным коэффициентам корреляции.

1. **$\rho = 1$**  
   Все точки лежат (почти наверняка) на **прямой с положительным наклоном**. Если мы возьмём выборку $(x_i, y_i)$, то они окажутся на одной прямой $y = a x + b$ с $a>0$.  
2. **$\rho = -1$**  
   Все точки лежат (почти наверняка) на **прямой с отрицательным наклоном**.  
3. **$\rho \approx 0.5$** (положительная корреляция)  
   Точки рассредоточены, но просматривается тенденция к росту $Y$ при росте $X$. Облако слегка вытянуто по диагонали с положительным наклоном.  
4. **$\rho \approx -0.5$** (отрицательная корреляция)  
   Аналогично, но с обратной зависимостью: при росте $X$ значения $Y$ в среднем убывают.  
5. **$\rho = 0$**  
   Облако может быть «круговым» или «рассеянным» без явной диагональной структуры (хотя может быть нелинейная зависимость).  

Графически:
- $\rho = 1$ — «идеальная» прямая вверх,
- $\rho = -1$ — «идеальная» прямая вниз,
- $\rho = 0$ — нет явной «наклонной» формы облака,
- $\rho = \pm 0.5$ — заметная, но не идеальная тенденция.

## 5. Ковариационная матрица для $n$-мерной случайной величины

Пусть есть $n$-мерный вектор случайных величин 
$$
\mathbf{X} = (X_1, X_2, \dots, X_n).
$$
**Ковариационная (или матрица ковариаций) матрица** определяется как
$$
\Sigma = \bigl[\mathrm{Cov}(X_i, X_j)\bigr]_{i,j=1}^n,
$$
то есть элемент $(i,j)$ — это $\mathrm{Cov}(X_i, X_j)$.

### 5.1. Что стоит на главной диагонали?

На главной диагонали ковариационной матрицы стоят
$$
\mathrm{Cov}(X_i, X_i) = \mathrm{Var}(X_i),
$$
то есть **дисперсии** соответствующих координат случайного вектора.

### 5.2. Свойства ковариационной матрицы

- **Симметричность**: $\Sigma = \Sigma^\mathsf{T}$.  
- **Положительная полуопределённость**: для любого вектора $a \in \mathbb{R}^n$ выполняется $a^\mathsf{T}\Sigma\, a \ge 0$.  

Эти свойства делают ковариационную матрицу фундаментальным объектом в многомерной статистике.

---

## 6. Итоговые тезисы

1. **Ковариация** $\mathrm{Cov}(X, Y)$ описывает «направление» (знак) и «интенсивность» (модуль) линейной связи между $X$ и $Y$.  
2. **Коэффициент корреляции** $\rho_{X,Y}$ нормирует ковариацию относительно стандартных отклонений и лежит в диапазоне $[-1, 1]$.  
3. **$\rho = \pm 1$** соответствует идеальной линейной зависимости (прямой), а $\rho=0$ означает отсутствие линейной зависимости (но не гарантирует независимость).  
4. **Диаграммы рассеяния** при различных $\rho$ иллюстрируют, как данные «вытягиваются» вдоль прямой с положительным или отрицательным наклоном либо «рассеиваются» без линейной тенденции.  
5. **Ковариационная матрица** для $n$-мерной случайной величины собирает в себе все ковариации и дисперсии (на главной диагонали), будучи симметричной и положительно полуопределённой.

> Билет: Совместный закон распределения двумерной дискретной случайной величины. Определение, процедура маргинализации, переход к функции распределения. Условные законы распределения. Пример и вычисление $E(X \mid Y=y)$

## 1. Определение совместного закона распределения двумерной дискретной с.в.

Пусть $(X, Y)$ — двумерная дискретная случайная величина. Это означает, что каждая из компонент $X$ и $Y$ принимает значения из некоторого (конечного или счётного) множества, например:
- $X$ принимает значения из $\{x_1, x_2, \dots\}$,
- $Y$ принимает значения из $\{y_1, y_2, \dots\}$.

Тогда **совместным (двумерным) законом распределения** называется система вероятностей
$$
p_{X,Y}(x_i, y_j) \;=\; P(X = x_i,\; Y = y_j),
$$
где сумма по всем $i,j$ равна 1:
$$
\sum_{i}\sum_{j} p_{X,Y}(x_i, y_j) = 1.
$$

## 2. [[маргинальные распределения|Маргинализация]](переход к одноимённым распределениям $X$ и $Y$)

Из совместного распределения можно получить **маргинальные** (или одномерные) распределения $X$ и $Y$:

- **Маргинальное распределение $X$**:
  $$
  p_X(x_i) = P(X = x_i) = \sum_{j} P(X = x_i,\; Y = y_j) 
            = \sum_{j} p_{X,Y}(x_i, y_j).
  $$

- **Маргинальное распределение $Y$**:
  $$
  p_Y(y_j) = P(Y = y_j) = \sum_{i} P(X = x_i,\; Y = y_j)
            = \sum_{i} p_{X,Y}(x_i, y_j).
  $$

Таким образом, «маргинальные» вероятности находятся суммированием по «другой» переменной.

## 3. Переход к функции распределения

Если $(X, Y)$ — двумерная дискретная с.в., то **двумерная функция распределения** $F_{X,Y}(a,b)$ определяется так:
$$
F_{X,Y}(a, b) \;=\; P(X \le a,\; Y \le b).
$$
Значит, при вычислении $F_{X,Y}(a,b)$ мы суммируем $p_{X,Y}(x_i, y_j)$ по всем $x_i \le a$ и $y_j \le b$.  
Далее, «срезы» этой функции можно использовать для поиска одномерных функций распределения $F_X(a) = P(X \le a)$, $F_Y(b) = P(Y \le b)$.

## 4. Условные законы распределения

### 4.1. Условное распределение $X$ при $Y=y_j$

Если $p_{X,Y}(x_i, y_j)$ и $p_Y(y_j) > 0$ известны, то **условная вероятность**:
$$
p_{X \mid Y}(x_i \mid y_j) 
= P(X = x_i \mid Y = y_j) 
= \frac{P(X = x_i,\; Y = y_j)}{P(Y = y_j)} 
= \frac{p_{X,Y}(x_i, y_j)}{p_Y(y_j)}.
$$
Все эти вероятности для фиксированного $y_j$ суммируются в 1:
$$
\sum_i p_{X \mid Y}(x_i \mid y_j) = 1.
$$

### 4.2. Условное распределение $Y$ при $X=x_i$

Аналогично,
$$
p_{Y \mid X}(y_j \mid x_i) 
= P(Y = y_j \mid X = x_i) 
= \frac{p_{X,Y}(x_i, y_j)}{p_X(x_i)}.
$$

## 5. Сквозной пример

Пусть $(X, Y)$ принимает значения из $\{0,1\}\times\{0,1\}$ со следующим совместным распределением:

|       | \(Y=0\) | \(Y=1\) | Сумма по \(X\) |
|:-----:|:-------:|:-------:|:--------------:|
|**\(X=0\)**| 0.10     | 0.30     | 0.40           |
|**\(X=1\)**| 0.20     | 0.40     | 0.60           |
|**Сумма по \(Y\)**| 0.30     | 0.70     | 1.00           |

Из таблицы видно:

- \(p_{X,Y}(0,0) = 0.10\), \(p_{X,Y}(0,1) = 0.30\),
- \(p_{X,Y}(1,0) = 0.20\), \(p_{X,Y}(1,1) = 0.40\).

**Маргинальные распределения**:

- \(p_X(0) = 0.10 + 0.30 = 0.40\),
- \(p_X(1) = 0.20 + 0.40 = 0.60\),

- \(p_Y(0) = 0.10 + 0.20 = 0.30\),
- \(p_Y(1) = 0.30 + 0.40 = 0.70\).

### 5.1. Условное распределение \(X\mid Y=0\)

$$
p_{X \mid Y}(0 \mid 0) 
= \frac{p_{X,Y}(0,0)}{p_Y(0)} 
= \frac{0.10}{0.30} = \frac{1}{3},
$$
$$
p_{X \mid Y}(1 \mid 0) 
= \frac{p_{X,Y}(1,0)}{p_Y(0)} 
= \frac{0.20}{0.30} = \frac{2}{3}.
$$

### 5.2. Условное распределение \(X\mid Y=1\)

$$
p_{X \mid Y}(0 \mid 1) 
= \frac{p_{X,Y}(0,1)}{p_Y(1)} 
= \frac{0.30}{0.70} = \frac{3}{7},
$$
$$
p_{X \mid Y}(1 \mid 1) 
= \frac{p_{X,Y}(1,1)}{p_Y(1)} 
= \frac{0.40}{0.70} = \frac{4}{7}.
$$

## 6. Как посчитать условное среднее значение $E(X \mid Y = y)$

**Условное математическое ожидание** $E(X \mid Y = y_j)$ определяется как сумма (или интеграл в непрерывном случае) по всем возможным $x_i$:

$$
E(X \mid Y = y_j) 
= \sum_i x_i \, p_{X \mid Y}(x_i \mid y_j).
$$

В нашем примере:

- **Если $Y=0$**:
  $$
  E(X \mid Y=0) 
  = 0 \cdot \tfrac13 + 1 \cdot \tfrac23 
  = 0 + \tfrac23 
  = \tfrac23.
  $$

- **Если $Y=1$**:
  $$
  E(X \mid Y=1) 
  = 0 \cdot \tfrac37 + 1 \cdot \tfrac47
  = 0 + \tfrac47
  = \tfrac47.
  $$

Таким образом, мы видим, что условное среднее $X$ зависит от того, какое значение принимает $Y$.

### 6.1. Что означают буквы $X, Y, y$ в этом выражении?

- $X$ и $Y$ — названия **случайных величин** (например, «количество успехов» и «тип исхода», «число деталей» и «число дефектов» и т.д.).
- $y$ — **конкретное значение** случайной величины $Y$. При $Y=y$, мы рассматриваем событие «$Y$ приняло значение $y$». Тогда $E(X \mid Y=y)$ означает «математическое ожидание $X$ при условии, что $Y$ уже известно и равно $y$».

## 7. Итог

1. **Совместное распределение** $(X,Y)$ задаёт вероятность $P(X=x_i, Y=y_j)$ для всех пар $(x_i, y_j)$.  
2. **Маргинализация**: чтобы найти распределение одной из компонент (например, $X$), суммируем совместные вероятности по всем значениям другой переменной.  
3. **Условное распределение** $X \mid Y=y_j$ вычисляется как отношение $p_{X,Y}(x_i,y_j)$ к $p_Y(y_j)$.  
4. **Условное среднее** $E(X \mid Y=y_j)$ — это сумма $x_i \, p_{X \mid Y}(x_i \mid y_j)$ по всем $x_i$.  
5. **Пример** с табличными значениями демонстрирует, как все эти понятия работают на практике.